{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3399185,"sourceType":"datasetVersion","datasetId":2049052}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T08:25:39.082319Z","iopub.execute_input":"2024-05-20T08:25:39.083075Z","iopub.status.idle":"2024-05-20T08:25:39.088070Z","shell.execute_reply.started":"2024-05-20T08:25:39.083039Z","shell.execute_reply":"2024-05-20T08:25:39.086942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Steps:** \n    \n    1)  Import libraries.\n\n    2)  Load data (and split into training & validation sets).\n\n    2.5)  Plot some images to see what the data looks like.\n\n    3) Set up a pre-train base of choice: MobileNetV2.\n\n    4) Attach extra layers to the base.\n\n    5) Train the model.\n\n    6) Create confusion matrix & classification performance.\n\n    7) Inspect correct and incorrect classification.\n","metadata":{}},{"cell_type":"markdown","source":"**To improve on later:** \n\n    1) Create a test set & evaluate performance on test set (Step 2, 6, 7)\n    2) Find a way to extract performance from training better.\n    3) Compare with different pre-trained base, other model configurations.","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:24:08.747105Z","iopub.execute_input":"2024-06-04T08:24:08.747546Z","iopub.status.idle":"2024-06-04T08:24:08.753995Z","shell.execute_reply.started":"2024-06-04T08:24:08.747494Z","shell.execute_reply":"2024-06-04T08:24:08.752407Z"}}},{"cell_type":"markdown","source":"### 1) Import libraries","metadata":{}},{"cell_type":"code","source":"# import basic libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\n\n# import tensorflow  \nfrom tensorflow import keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow import data\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# from keras.applications.resnet50 import ResNet50\n# from keras.applications.resnet50 import preprocess_input, decode_predictions\n# from tensorflow.keras.layers.experimental import preprocessing\n\n# Plotting \nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:02:44.112197Z","iopub.execute_input":"2024-06-04T08:02:44.112847Z","iopub.status.idle":"2024-06-04T08:02:44.118212Z","shell.execute_reply.started":"2024-06-04T08:02:44.112811Z","shell.execute_reply":"2024-06-04T08:02:44.117225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Load data","metadata":{}},{"cell_type":"code","source":"# set path to data directory\npath = Path('/kaggle/input/rice-image-dataset/Rice_Image_Dataset')\n\n# check files in the directory\nlist(path.glob('*'))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:16:37.607706Z","iopub.execute_input":"2024-06-04T06:16:37.608462Z","iopub.status.idle":"2024-06-04T06:16:37.628675Z","shell.execute_reply.started":"2024-06-04T06:16:37.608428Z","shell.execute_reply":"2024-06-04T06:16:37.627685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nIMAGE_SIZE=(224, 224)\nBATCH_SIZE=32\n\n\n# Create training and validation sets\norig_data = keras.preprocessing.image_dataset_from_directory(directory=path,\n                                                        labels='inferred',\n                                                        label_mode ='categorical',\n                                                        image_size=IMAGE_SIZE,\n                                                        subset='both',\n                                                        batch_size=BATCH_SIZE,\n                                                        validation_split=0.2,\n                                                        shuffle=True,\n                                                        seed=42)\n\ntrain_dataset = orig_data[0]\nvalidation_dataset = orig_data[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:36:45.626898Z","iopub.execute_input":"2024-06-04T06:36:45.627650Z","iopub.status.idle":"2024-06-04T06:37:04.068029Z","shell.execute_reply.started":"2024-06-04T06:36:45.627618Z","shell.execute_reply":"2024-06-04T06:37:04.067064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check number of batches\nprint('Number of training batches: %d' % data.experimental.cardinality(train_dataset))\nprint('Number of validation  batches: %d' % data.experimental.cardinality(validation_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:09.320880Z","iopub.execute_input":"2024-06-04T06:37:09.321616Z","iopub.status.idle":"2024-06-04T06:37:09.327953Z","shell.execute_reply.started":"2024-06-04T06:37:09.321581Z","shell.execute_reply":"2024-06-04T06:37:09.326871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check class distribution\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:29:33.348323Z","iopub.execute_input":"2024-06-04T07:29:33.348952Z","iopub.status.idle":"2024-06-04T07:29:33.354723Z","shell.execute_reply.started":"2024-06-04T07:29:33.348918Z","shell.execute_reply":"2024-06-04T07:29:33.353823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5) Plot some images","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:09:22.262240Z","iopub.execute_input":"2024-05-20T07:09:22.262601Z","iopub.status.idle":"2024-05-20T07:09:22.266869Z","shell.execute_reply.started":"2024-05-20T07:09:22.262574Z","shell.execute_reply":"2024-05-20T07:09:22.265723Z"}}},{"cell_type":"code","source":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(15, 4))\nfor images, labels in train_dataset.take(1): # take data from batch 1 (32 items)\n    for i in range(20):\n        ax = plt.subplot(2, 10, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        ind = np.where(labels[i] == 1)[0][0]\n        plt.title(class_names[ind])\n#         plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:26.626721Z","iopub.execute_input":"2024-06-04T06:37:26.627453Z","iopub.status.idle":"2024-06-04T06:37:28.344271Z","shell.execute_reply.started":"2024-06-04T06:37:26.627412Z","shell.execute_reply":"2024-06-04T06:37:28.343257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Set up a pre-trained base","metadata":{"execution":{"iopub.status.busy":"2024-05-20T06:32:28.491270Z","iopub.execute_input":"2024-05-20T06:32:28.491609Z","iopub.status.idle":"2024-05-20T06:32:28.495636Z","shell.execute_reply.started":"2024-05-20T06:32:28.491585Z","shell.execute_reply":"2024-05-20T06:32:28.494629Z"}}},{"cell_type":"code","source":"# Create the base model from the pre-trained model MobileNet V2\nIMAGE_SHAPE = IMAGE_SIZE + (3,)\nbase_model = keras.applications.MobileNetV2(input_shape=IMAGE_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:39:40.176664Z","iopub.execute_input":"2024-06-04T06:39:40.177622Z","iopub.status.idle":"2024-06-04T06:39:40.942010Z","shell.execute_reply.started":"2024-06-04T06:39:40.177584Z","shell.execute_reply":"2024-06-04T06:39:40.940897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check features extracted from the base\nimage_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:39:43.593314Z","iopub.execute_input":"2024-06-04T06:39:43.594066Z","iopub.status.idle":"2024-06-04T06:39:43.906027Z","shell.execute_reply.started":"2024-06-04T06:39:43.594033Z","shell.execute_reply":"2024-06-04T06:39:43.904978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set trainable to False\nbase_model.trainable = False\n\n# Check the structure of the base model\n# base_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:51:00.355550Z","iopub.execute_input":"2024-06-04T06:51:00.355970Z","iopub.status.idle":"2024-06-04T06:51:00.360475Z","shell.execute_reply.started":"2024-06-04T06:51:00.355938Z","shell.execute_reply":"2024-06-04T06:51:00.359650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Add global average pooling layer \nglobal_average_layer = keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(base_model.output)\n\nprint(feature_batch_average.shape)\n\n\n# Add prediction later\nprediction_layer = keras.layers.Dense(5, activation='softmax')\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:51:36.403303Z","iopub.execute_input":"2024-06-04T06:51:36.403665Z","iopub.status.idle":"2024-06-04T06:51:36.420267Z","shell.execute_reply.started":"2024-06-04T06:51:36.403635Z","shell.execute_reply":"2024-06-04T06:51:36.419371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) Attach extra layers to the base","metadata":{}},{"cell_type":"code","source":"# Putting all the layers together\nmodel = keras.Sequential([base_model,\n                          global_average_layer,\n                          prediction_layer\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:51:38.544135Z","iopub.execute_input":"2024-06-04T06:51:38.544502Z","iopub.status.idle":"2024-06-04T06:51:38.550081Z","shell.execute_reply.started":"2024-06-04T06:51:38.544472Z","shell.execute_reply":"2024-06-04T06:51:38.549170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary(line_length=100)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:51:40.521724Z","iopub.execute_input":"2024-06-04T06:51:40.522549Z","iopub.status.idle":"2024-06-04T06:51:40.548649Z","shell.execute_reply.started":"2024-06-04T06:51:40.522519Z","shell.execute_reply":"2024-06-04T06:51:40.547802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Train the model","metadata":{}},{"cell_type":"code","source":"optimizer = keras.optimizers.Adam(epsilon=0.0001)\nmodel.compile(\n    optimizer=optimizer,\n    loss = \"categorical_crossentropy\",\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:54:26.750802Z","iopub.execute_input":"2024-06-04T06:54:26.751608Z","iopub.status.idle":"2024-06-04T06:54:26.995906Z","shell.execute_reply.started":"2024-06-04T06:54:26.751578Z","shell.execute_reply":"2024-06-04T06:54:26.994827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:54:35.754571Z","iopub.execute_input":"2024-06-04T06:54:35.755273Z","iopub.status.idle":"2024-06-04T07:06:26.181408Z","shell.execute_reply.started":"2024-06-04T06:54:35.755242Z","shell.execute_reply":"2024-06-04T07:06:26.180619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate on validation dataset (should ideally be independent test set)\n# loss0, accuracy0 = model.evaluate(validation_dataset)\n# print(\"initial loss: {:.2f}\".format(loss0))\n# print(\"initial accuracy: {:.2f}\".format(accuracy0))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:19:56.935688Z","iopub.execute_input":"2024-06-04T07:19:56.936602Z","iopub.status.idle":"2024-06-04T07:19:56.940554Z","shell.execute_reply.started":"2024-06-04T07:19:56.936565Z","shell.execute_reply":"2024-06-04T07:19:56.939617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check on possible keys\nprint(history.history.keys())","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:19:40.791991Z","iopub.execute_input":"2024-06-04T07:19:40.792400Z","iopub.status.idle":"2024-06-04T07:19:40.797962Z","shell.execute_reply.started":"2024-06-04T07:19:40.792367Z","shell.execute_reply":"2024-06-04T07:19:40.796921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot learning curves for training and validation data\n\n# Accuracy\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Plot training & validation accuracy\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\n# Plot training & validation loss\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Categorical Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:15:17.818776Z","iopub.execute_input":"2024-06-04T07:15:17.819430Z","iopub.status.idle":"2024-06-04T07:15:18.285680Z","shell.execute_reply.started":"2024-06-04T07:15:17.819397Z","shell.execute_reply":"2024-06-04T07:15:18.284126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6) Confusion matrix & classification performance","metadata":{}},{"cell_type":"code","source":"# Retrieve a batch of images from the validation set\nimage_batch, label_batch = validation_dataset.as_numpy_iterator().next()\npredictions = model.predict(image_batch)\n\n# Formatting\ny_true = np.argmax(label_batch, axis=1)\ny_pred = np.argmax(predictions, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:56:24.228743Z","iopub.execute_input":"2024-06-04T07:56:24.229359Z","iopub.status.idle":"2024-06-04T07:56:24.391773Z","shell.execute_reply.started":"2024-06-04T07:56:24.229326Z","shell.execute_reply":"2024-06-04T07:56:24.391011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confution Matrix and Classification Report\nprint('Confusion Matrix')\nprint(confusion_matrix(y_true, y_pred))\nprint('----------------')\nprint('Classification Report')\ntarget_names = validation_dataset.class_names\nprint(classification_report(y_true, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:04:34.713127Z","iopub.execute_input":"2024-06-04T08:04:34.713845Z","iopub.status.idle":"2024-06-04T08:04:34.728867Z","shell.execute_reply.started":"2024-06-04T08:04:34.713810Z","shell.execute_reply":"2024-06-04T08:04:34.727835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7) Examples of correct and incorrect classification","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nfor images, labels in validation_dataset.take(1):\n    for i in range(20):\n        ax = plt.subplot(5, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        ind = np.where(labels[i] == 1)[0][0]\n        y_pred_ind = y_pred[i]\n        plt.title(class_names[ind] + \" (T), \" + class_names[y_pred_ind] + \" (P) \")\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:16:19.741913Z","iopub.execute_input":"2024-06-04T08:16:19.742767Z","iopub.status.idle":"2024-06-04T08:16:21.370717Z","shell.execute_reply.started":"2024-06-04T08:16:19.742722Z","shell.execute_reply":"2024-06-04T08:16:21.369808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Codes are adapted from various sources: \n    \n    - https://www.tensorflow.org/tutorials/images/transfer_learning","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:17:33.338095Z","iopub.execute_input":"2024-06-04T08:17:33.338978Z","iopub.status.idle":"2024-06-04T08:17:33.345058Z","shell.execute_reply.started":"2024-06-04T08:17:33.338945Z","shell.execute_reply":"2024-06-04T08:17:33.343798Z"}}}]}